"""
ç¬¬ä¸€ä¸ªLangChainç¨‹åº - æœ€ç®€å•çš„AIè°ƒç”¨

å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£å¦‚ä½•å¯¼å…¥å’Œåˆå§‹åŒ–LangChainæ¨¡å‹
2. æŒæ¡æœ€åŸºæœ¬çš„AIè°ƒç”¨æ–¹æ³•
3. äº†è§£å¦‚ä½•å¤„ç†AIçš„å“åº”

å¯¹æ¯”Spring-AIï¼š
åœ¨Spring-AIä¸­ï¼Œä½ å¯èƒ½è¿™æ ·å†™ï¼š
    @Autowired
    private ChatClient chatClient;
    String response = chatClient.call("ä½ å¥½");
    
åœ¨LangChainä¸­ï¼Œä¸éœ€è¦ä¾èµ–æ³¨å…¥ï¼Œç›´æ¥åˆ›å»ºå¯¹è±¡å³å¯
"""

import os
from dotenv import load_dotenv

# ============================================================================
# ç¬¬ä¸€æ­¥ï¼šåŠ è½½ç¯å¢ƒå˜é‡ï¼ˆè¯»å–.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥ï¼‰
# ============================================================================
load_dotenv()  # è¿™ä¼šè‡ªåŠ¨è¯»å–å½“å‰ç›®å½•ä¸‹çš„.envæ–‡ä»¶

# ä»ç¯å¢ƒå˜é‡ä¸­è·å–APIå¯†é’¥
# ç±»ä¼¼äºSpring Bootçš„ @Value("${openai.api.key}")
api_key = os.getenv("OPENAI_API_KEY")

# æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
if not api_key:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°OPENAI_API_KEY")
    print("è¯·å…ˆåˆ›å»º.envæ–‡ä»¶å¹¶è®¾ç½®APIå¯†é’¥")
    exit(1)


# ============================================================================
# ç¬¬äºŒæ­¥ï¼šå¯¼å…¥LangChainçš„OpenAIæ¨¡å‹
# ============================================================================
from langchain_openai import ChatOpenAI

# ChatOpenAI æ˜¯LangChainå¯¹OpenAIèŠå¤©æ¨¡å‹çš„å°è£…
# ç±»ä¼¼äºSpring-AIä¸­çš„ChatClient


# ============================================================================
# ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºæ¨¡å‹å®ä¾‹
# ============================================================================
print("æ­£åœ¨åˆå§‹åŒ–AIæ¨¡å‹...")

llm = ChatOpenAI(
    # æ¨¡å‹åç§°ï¼Œgpt-3.5-turboæ˜¯æœ€å¸¸ç”¨çš„æ¨¡å‹
    # å…¶ä»–é€‰é¡¹ï¼šgpt-4, gpt-4-turboç­‰
    model="qwen2.5-vl-72b-instruct",
    
    # temperatureæ§åˆ¶å›å¤çš„éšæœºæ€§
    # 0 = éå¸¸ç¡®å®šï¼Œå›å¤å›ºå®š
    # 1 = å¾ˆéšæœºï¼Œå›å¤å¤šæ ·
    # æ¨èå€¼ï¼š0.7
    temperature=0.7,
    
    # APIå¯†é’¥
    api_key=api_key,
    
    # APIåŸºç¡€URLï¼ˆå¦‚æœä½¿ç”¨ä»£ç†æˆ–Azure OpenAIéœ€è¦ä¿®æ”¹ï¼‰
    base_url=os.getenv("OPENAI_API_BASE", "http://192.168.2.54:9015/v1/")
)

print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼\n")


# ============================================================================
# ç¬¬å››æ­¥ï¼šå‘é€ç¬¬ä¸€æ¡æ¶ˆæ¯
# ============================================================================
print("=" * 60)
print("ç¤ºä¾‹1ï¼šæœ€ç®€å•çš„è°ƒç”¨")
print("=" * 60)

# ä½¿ç”¨invokeæ–¹æ³•å‘é€æ¶ˆæ¯ï¼ˆç±»ä¼¼Spring-AIçš„callæ–¹æ³•ï¼‰
response = llm.invoke("ä½ å¥½ï¼è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")

# responseæ˜¯ä¸€ä¸ªAIMessageå¯¹è±¡ï¼ŒåŒ…å«å¤šä¸ªå±æ€§
# response.content æ˜¯AIçš„å›å¤å†…å®¹ï¼ˆæœ€å¸¸ç”¨ï¼‰
# response.response_metadata åŒ…å«tokenä½¿ç”¨é‡ç­‰ä¿¡æ¯

print(f"ç”¨æˆ·: ä½ å¥½ï¼è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")
print(f"AI: {response.content}")
print()


# ============================================================================
# ç¬¬äº”æ­¥ï¼šæŸ¥çœ‹å“åº”çš„è¯¦ç»†ä¿¡æ¯
# ============================================================================
print("=" * 60)
print("å“åº”å¯¹è±¡çš„è¯¦ç»†ä¿¡æ¯")
print("=" * 60)

# æ‰“å°å“åº”å¯¹è±¡çš„ç±»å‹
print(f"å“åº”ç±»å‹: {type(response)}")

# æ‰“å°AIå›å¤çš„å†…å®¹
print(f"å›å¤å†…å®¹: {response.content}")

# æ‰“å°å…ƒæ•°æ®ï¼ˆåŒ…å«tokenä½¿ç”¨é‡ç­‰ä¿¡æ¯ï¼‰
if hasattr(response, 'response_metadata'):
    print(f"å…ƒæ•°æ®: {response.response_metadata}")
    
    # è·å–tokenä½¿ç”¨é‡ï¼ˆé‡è¦ï¼šå…³ç³»åˆ°è´¹ç”¨ï¼‰
    if 'token_usage' in response.response_metadata:
        usage = response.response_metadata['token_usage']
        print(f"\nğŸ“Š Tokenä½¿ç”¨æƒ…å†µ:")
        print(f"  - è¾“å…¥token: {usage.get('prompt_tokens', 0)}")
        print(f"  - è¾“å‡ºtoken: {usage.get('completion_tokens', 0)}")
        print(f"  - æ€»è®¡: {usage.get('total_tokens', 0)}")

print()


# ============================================================================
# ç¬¬å…­æ­¥ï¼šè¿ç»­å¯¹è¯ç¤ºä¾‹
# ============================================================================
print("=" * 60)
print("ç¤ºä¾‹2ï¼šå¤šè½®å¯¹è¯")
print("=" * 60)

# å®šä¹‰ä¸€äº›é—®é¢˜
questions = [
    "Pythonå’ŒJavaçš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
    "è¯·ä¸¾ä¸€ä¸ªPythonçš„ç®€å•ä¾‹å­",
]

# å¾ªç¯æé—®
for i, question in enumerate(questions, 1):
    print(f"\nã€ç¬¬{i}è½®å¯¹è¯ã€‘")
    print(f"ç”¨æˆ·: {question}")
    
    # å‘é€æ¶ˆæ¯
    response = llm.invoke(question)
    
    # æ‰“å°å›å¤
    print(f"AI: {response.content}")


# ============================================================================
# æ€»ç»“
# ============================================================================
print("\n" + "=" * 60)
print("âœ… æ­å–œï¼ä½ å·²ç»å®Œæˆäº†ç¬¬ä¸€ä¸ªLangChainç¨‹åº")
print("=" * 60)
print("""
å…³é”®æ¦‚å¿µå›é¡¾ï¼š
1. ChatOpenAI - æ¨¡å‹ç±»ï¼ˆç±»ä¼¼Spring-AIçš„ChatClientï¼‰
2. invoke() - å‘é€æ¶ˆæ¯çš„æ–¹æ³•ï¼ˆç±»ä¼¼Spring-AIçš„call()ï¼‰
3. response.content - è·å–AIå›å¤å†…å®¹
4. temperature - æ§åˆ¶å›å¤çš„éšæœºæ€§

ä¸‹ä¸€æ­¥ï¼š
- å­¦ä¹ å¦‚ä½•ä½¿ç”¨æ¶ˆæ¯å†å²ï¼ˆå®ç°çœŸæ­£çš„å¯¹è¯ï¼‰
- å­¦ä¹ å¦‚ä½•ä½¿ç”¨æç¤ºè¯æ¨¡æ¿
- å­¦ä¹ å¦‚ä½•å¤„ç†æµå¼è¾“å‡º

ç»§ç»­åŠ æ²¹ï¼ğŸš€
""")

