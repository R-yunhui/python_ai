# RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) å­¦ä¹ æŒ‡å—

## ğŸ¯ ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

**RAG (Retrieval-Augmented Generation)** æ˜¯ä¸€ç§ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯ï¼š

1. **æ£€ç´¢ï¼ˆRetrievalï¼‰**ï¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£
2. **å¢å¼ºï¼ˆAugmentedï¼‰**ï¼šå°†æ£€ç´¢åˆ°çš„æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡
3. **ç”Ÿæˆï¼ˆGenerationï¼‰**ï¼šLLM åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ

### ä¸ºä»€ä¹ˆéœ€è¦ RAGï¼Ÿ

| é—®é¢˜ | RAG è§£å†³æ–¹æ¡ˆ |
|------|-------------|
| LLM çŸ¥è¯†æœ‰æ—¶æ•ˆæ€§ | å®æ—¶æ£€ç´¢æœ€æ–°çŸ¥è¯† |
| LLM æ— æ³•è®¿é—®ç§æœ‰æ•°æ® | ä»ä¼ä¸šçŸ¥è¯†åº“æ£€ç´¢ |
| LLM å¯èƒ½äº§ç”Ÿå¹»è§‰ | åŸºäºçœŸå®æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ |
| ä¸Šä¸‹æ–‡é•¿åº¦æœ‰é™ | åªæ£€ç´¢ç›¸å…³éƒ¨åˆ† |

---

## ğŸ“š å­¦ä¹ è·¯å¾„

### ç¬¬1é˜¶æ®µï¼šåŸºç¡€ RAG
**æ–‡ä»¶ï¼š`01_basic_rag.py`**

å­¦ä¹ å†…å®¹ï¼š
- âœ… æ–‡æ¡£åŠ è½½ï¼ˆTextLoader, DirectoryLoaderï¼‰
- âœ… æ–‡æœ¬åˆ‡åˆ†ï¼ˆRecursiveCharacterTextSplitterï¼‰
- âœ… å‘é‡åŒ–ï¼ˆOpenAIEmbeddingsï¼‰
- âœ… å‘é‡å­˜å‚¨ï¼ˆFAISS å†…å­˜å­˜å‚¨ï¼‰
- âœ… ç›¸ä¼¼åº¦æ£€ç´¢
- âœ… ç­”æ¡ˆç”Ÿæˆ

**è¿è¡Œç¤ºä¾‹ï¼š**
```bash
cd langchain_demo/04_rag
python 01_basic_rag.py
```

**æ ¸å¿ƒä»£ç ï¼š**
```python
# 1. åŠ è½½æ–‡æ¡£
loader = DirectoryLoader("documents/", glob="*.txt")
documents = loader.load()

# 2. åˆ‡åˆ†æ–‡æ¡£
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(documents)

# 3. åˆ›å»ºå‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings()
vector_store = FAISS.from_documents(chunks, embeddings)

# 4. æ£€ç´¢ç›¸å…³æ–‡æ¡£
docs = vector_store.similarity_search(query, k=4)

# 5. ç”Ÿæˆç­”æ¡ˆ
context = "\n\n".join([doc.page_content for doc in docs])
answer = llm.invoke(f"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\n{context}\n\né—®é¢˜ï¼š{query}")
```

---

### ç¬¬2é˜¶æ®µï¼šMilvus é›†æˆ
**æ–‡ä»¶ï¼š`02_milvus_integration.py`**

å­¦ä¹ å†…å®¹ï¼š
- âœ… Milvus å‘é‡æ•°æ®åº“è¿æ¥
- âœ… åˆ›å»ºæŒä¹…åŒ–å‘é‡é›†åˆ
- âœ… é«˜çº§æ£€ç´¢åŠŸèƒ½ï¼ˆMMRã€å¸¦åˆ†æ•°æ£€ç´¢ï¼‰
- âœ… å¢é‡æ·»åŠ æ–‡æ¡£
- âœ… æ–‡æ¡£åˆ é™¤å’Œç®¡ç†

**Milvus ä¼˜åŠ¿ï¼š**
- ğŸ’¾ æŒä¹…åŒ–å­˜å‚¨
- ğŸš€ æ”¯æŒäº¿çº§å‘é‡
- ğŸ”§ ä¸°å¯Œçš„ç´¢å¼•ç±»å‹
- ğŸ“Š åˆ†å¸ƒå¼éƒ¨ç½²
- ğŸ” æ··åˆæ£€ç´¢ï¼ˆå‘é‡+æ ‡é‡è¿‡æ»¤ï¼‰

**è¿è¡Œç¤ºä¾‹ï¼š**
```bash
# ç¡®ä¿ Milvus å·²å¯åŠ¨
python 02_milvus_integration.py
```

**æ ¸å¿ƒä»£ç ï¼š**
```python
from langchain_milvus import Milvus

# åˆ›å»º Milvus å‘é‡å­˜å‚¨
vector_store = Milvus.from_documents(
    documents=chunks,
    embedding=embeddings,
    collection_name="knowledge_base",
    connection_args={"host": "localhost", "port": "19530"}
)

# æ£€ç´¢
docs = vector_store.similarity_search(query, k=4)

# MMR æ£€ç´¢ï¼ˆå¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§ï¼‰
docs_mmr = vector_store.max_marginal_relevance_search(query, k=4)
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### `config.py` é…ç½®æ–‡ä»¶

æ‰€æœ‰é…ç½®é¡¹éƒ½åœ¨ `config.py` ä¸­é›†ä¸­ç®¡ç†ï¼š

```python
# LLM é…ç½®
class LLMConfig:
    API_BASE = "http://your-api-base/v1/"
    MODEL = "qwen2.5-vl-72b-instruct"
    TEMPERATURE = 0.3

# Embedding é…ç½®
class EmbeddingConfig:
    MODEL = "text-embedding-3-small"
    DIMENSION = 1536

# Milvus é…ç½®
class MilvusConfig:
    HOST = "localhost"
    PORT = "19530"
    COLLECTION_NAME = "langchain_demo_knowledge_base"
    INDEX_TYPE = "IVF_FLAT"
    METRIC_TYPE = "L2"
```

**ä¿®æ”¹é…ç½®ï¼š**
1. ç›´æ¥ç¼–è¾‘ `config.py`
2. æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰ï¼š
```bash
export MILVUS_HOST=192.168.1.100
export MILVUS_PORT=19530
```

---

## ğŸ“‚ ç›®å½•ç»“æ„

```
04_rag/
â”œâ”€â”€ config.py                    # é…ç½®æ–‡ä»¶
â”œâ”€â”€ README.md                    # æœ¬æ–‡ä»¶
â”œâ”€â”€ 01_basic_rag.py             # åŸºç¡€ RAG ç¤ºä¾‹
â”œâ”€â”€ 02_milvus_integration.py    # Milvus é›†æˆç¤ºä¾‹
â””â”€â”€ documents/                   # ç¤ºä¾‹æ–‡æ¡£ç›®å½•
    â”œâ”€â”€ python_basics.txt        # Python åŸºç¡€çŸ¥è¯†
    â”œâ”€â”€ langchain_intro.txt      # LangChain ä»‹ç»
    â””â”€â”€ milvus_guide.txt         # Milvus æŒ‡å—
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd langchain_demo
pip install -r requirements.txt
```

ä¸»è¦ä¾èµ–ï¼š
- `langchain` - æ ¸å¿ƒæ¡†æ¶
- `langchain-openai` - OpenAI é›†æˆ
- `langchain-milvus` - Milvus é›†æˆ
- `pymilvus` - Milvus Python SDK
- `faiss-cpu` - FAISS å‘é‡å­˜å‚¨
- `pypdf` - PDF æ–‡æ¡£åŠ è½½
- `python-docx` - Word æ–‡æ¡£åŠ è½½

### 2. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```bash
OPENAI_API_BASE=http://your-api-base/v1/
OPENAI_API_KEY=your-api-key
OPENAI_MODEL=qwen2.5-vl-72b-instruct
EMBEDDING_MODEL=text-embedding-3-small

# Milvus é…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
MILVUS_HOST=localhost
MILVUS_PORT=19530
```

### 3. å‡†å¤‡æ–‡æ¡£

å°†ä½ çš„çŸ¥è¯†åº“æ–‡æ¡£æ”¾åˆ° `documents/` ç›®å½•ï¼š
- æ”¯æŒæ ¼å¼ï¼š`.txt`, `.md`, `.pdf`, `.docx`
- æ–‡æ¡£ä¼šè‡ªåŠ¨åŠ è½½å’Œå¤„ç†

### 4. è¿è¡Œç¤ºä¾‹

```bash
# åŸºç¡€ RAGï¼ˆä½¿ç”¨ FAISSï¼‰
python 01_basic_rag.py

# Milvus RAGï¼ˆéœ€è¦ Milvus è¿è¡Œï¼‰
python 02_milvus_integration.py
```

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. æ–‡æ¡£åŠ è½½å™¨ï¼ˆDocument Loadersï¼‰

**ä½œç”¨ï¼š** å°†å„ç§æ ¼å¼çš„æ–‡æ¡£è½¬æ¢ä¸º LangChain çš„ Document å¯¹è±¡ã€‚

```python
# æ–‡æœ¬æ–‡ä»¶
from langchain_community.document_loaders import TextLoader
loader = TextLoader("document.txt", encoding='utf-8')

# PDF æ–‡ä»¶
from langchain_community.document_loaders import PyPDFLoader
loader = PyPDFLoader("document.pdf")

# Word æ–‡æ¡£
from langchain_community.document_loaders import Docx2txtLoader
loader = Docx2txtLoader("document.docx")

# æ‰¹é‡åŠ è½½ç›®å½•
from langchain_community.document_loaders import DirectoryLoader
loader = DirectoryLoader("documents/", glob="*.txt")

documents = loader.load()
```

### 2. æ–‡æœ¬åˆ‡åˆ†å™¨ï¼ˆText Splittersï¼‰

**ä½œç”¨ï¼š** å°†é•¿æ–‡æ¡£åˆ‡åˆ†æˆé€‚åˆ LLM å¤„ç†çš„å°å—ã€‚

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,        # æ¯å—çš„å­—ç¬¦æ•°
    chunk_overlap=50,      # å—ä¹‹é—´çš„é‡å 
    separators=[           # åˆ†éš”ç¬¦ä¼˜å…ˆçº§
        "\n\n",            # æ®µè½
        "\n",              # è¡Œ
        "ã€‚",              # å¥å­
        " ",               # å•è¯
        ""                 # å­—ç¬¦
    ]
)

chunks = splitter.split_documents(documents)
```

**ä¸ºä»€ä¹ˆéœ€è¦åˆ‡åˆ†ï¼Ÿ**
- âœ… LLM ä¸Šä¸‹æ–‡é•¿åº¦æœ‰é™
- âœ… å°å—æ›´ç²¾ç¡®ï¼Œæ£€ç´¢æ›´å‡†ç¡®
- âœ… æé«˜æ£€ç´¢æ•ˆç‡
- âœ… æ›´å¥½çš„è¯­ä¹‰åˆ†å‰²

### 3. Embedding æ¨¡å‹

**ä½œç”¨ï¼š** å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_base="http://your-api/v1/",
    openai_api_key="your-key"
)

# å‘é‡åŒ–å•ä¸ªæ–‡æœ¬
vector = embeddings.embed_query("è¿™æ˜¯ä¸€æ®µæ–‡æœ¬")

# æ‰¹é‡å‘é‡åŒ–
vectors = embeddings.embed_documents(["æ–‡æœ¬1", "æ–‡æœ¬2"])
```

**å¸¸ç”¨ Embedding æ¨¡å‹ï¼š**
| æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ |
|------|------|------|
| text-embedding-3-small | 1536 | å¿«é€Ÿã€ç»æµ |
| text-embedding-3-large | 3072 | æ›´é«˜ç²¾åº¦ |
| text-embedding-ada-002 | 1536 | ç¨³å®šå¯é  |

### 4. å‘é‡å­˜å‚¨ï¼ˆVector Storesï¼‰

**ä½œç”¨ï¼š** å­˜å‚¨å’Œæ£€ç´¢å‘é‡ã€‚

#### FAISSï¼ˆå†…å­˜å­˜å‚¨ï¼‰
```python
from langchain_community.vectorstores import FAISS

vector_store = FAISS.from_documents(chunks, embeddings)

# ä¿å­˜åˆ°æœ¬åœ°
vector_store.save_local("faiss_index")

# ä»æœ¬åœ°åŠ è½½
vector_store = FAISS.load_local("faiss_index", embeddings)
```

#### Milvusï¼ˆæŒä¹…åŒ–å­˜å‚¨ï¼‰
```python
from langchain_milvus import Milvus

vector_store = Milvus.from_documents(
    documents=chunks,
    embedding=embeddings,
    collection_name="knowledge_base",
    connection_args={"host": "localhost", "port": "19530"}
)
```

### 5. æ£€ç´¢å™¨ï¼ˆRetrieversï¼‰

**ä½œç”¨ï¼š** ä»å‘é‡å­˜å‚¨ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚

```python
# æ–¹æ³•1ï¼šç›¸ä¼¼åº¦æœç´¢
docs = vector_store.similarity_search(query, k=4)

# æ–¹æ³•2ï¼šå¸¦åˆ†æ•°çš„æœç´¢
docs_with_scores = vector_store.similarity_search_with_score(query, k=4)

# æ–¹æ³•3ï¼šMMR æœç´¢ï¼ˆå¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§ï¼‰
docs_mmr = vector_store.max_marginal_relevance_search(
    query,
    k=4,
    fetch_k=20,
    lambda_mult=0.5
)

# æ–¹æ³•4ï¼šåˆ›å»ºæ£€ç´¢å™¨å¯¹è±¡
retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 4}
)
docs = retriever.get_relevant_documents(query)
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æ–‡æ¡£é¢„å¤„ç†

```python
# æ¸…ç†æ–‡æ¡£
def clean_document(text: str) -> str:
    # ç§»é™¤å¤šä½™ç©ºç™½
    text = re.sub(r'\s+', ' ', text)
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
    return text.strip()

# æ·»åŠ å…ƒæ•°æ®
for doc in documents:
    doc.metadata['category'] = 'technical'
    doc.metadata['author'] = 'AI Team'
```

### 2. é€‰æ‹©åˆé€‚çš„ Chunk Size

| åœºæ™¯ | Chunk Size | Overlap |
|------|-----------|---------|
| é—®ç­”ç³»ç»Ÿ | 300-500 | 50-100 |
| æ–‡æ¡£æ€»ç»“ | 1000-2000 | 100-200 |
| ä»£ç ç‰‡æ®µ | 500-1000 | 100 |

### 3. ä¼˜åŒ–æ£€ç´¢ç»“æœ

```python
# è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
def filter_by_score(docs_with_scores, threshold=0.5):
    return [doc for doc, score in docs_with_scores if score < threshold]

# é‡æ’åºï¼ˆä½¿ç”¨é‡æ’åºæ¨¡å‹ï¼‰
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

compressor = LLMChainExtractor.from_llm(llm)
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=retriever
)
```

### 4. æ··åˆæ£€ç´¢

```python
# ç»“åˆå…³é”®è¯æœç´¢å’Œå‘é‡æœç´¢
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

# BM25 å…³é”®è¯æ£€ç´¢
bm25_retriever = BM25Retriever.from_documents(chunks)
bm25_retriever.k = 4

# å‘é‡æ£€ç´¢
vector_retriever = vector_store.as_retriever(search_kwargs={"k": 4})

# ç»„åˆæ£€ç´¢å™¨
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=[0.5, 0.5]
)
```

### 5. æç¤ºè¯å·¥ç¨‹

```python
RAG_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

é‡è¦è§„åˆ™ï¼š
1. åªä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„ä¿¡æ¯å›ç­”
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®å‘Šè¯‰ç”¨æˆ·
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æœ‰æ¡ç†
4. å¯ä»¥å¼•ç”¨ä¸Šä¸‹æ–‡ä¸­çš„å…·ä½“å†…å®¹

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

ä½ çš„å›ç­”ï¼š
"""
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: å‘é‡åŒ–å¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

**A:** æ‰¹é‡å¤„ç†æ–‡æ¡£
```python
# è®¾ç½®æ‰¹é‡å¤§å°
embeddings = OpenAIEmbeddings(chunk_size=100)

# ä½¿ç”¨å¼‚æ­¥
import asyncio
vectors = await embeddings.aembed_documents(texts)
```

### Q2: æ£€ç´¢ç»“æœä¸ç›¸å…³ï¼Ÿ

**A:** ä¼˜åŒ–ç­–ç•¥
1. è°ƒæ•´ chunk_size å’Œ overlap
2. æ”¹è¿›æ–‡æ¡£é¢„å¤„ç†
3. å°è¯•ä¸åŒçš„ Embedding æ¨¡å‹
4. ä½¿ç”¨æ··åˆæ£€ç´¢
5. æ·»åŠ é‡æ’åº

### Q3: Milvus è¿æ¥å¤±è´¥ï¼Ÿ

**A:** æ£€æŸ¥æ¸…å•
```bash
# 1. æ£€æŸ¥ Milvus æ˜¯å¦è¿è¡Œ
docker ps | grep milvus

# 2. æ£€æŸ¥ç«¯å£
netstat -an | grep 19530

# 3. æµ‹è¯•è¿æ¥
python -c "from pymilvus import connections; connections.connect('default', host='localhost', port='19530'); print('OK')"
```

### Q4: å†…å­˜å ç”¨è¿‡é«˜ï¼Ÿ

**A:** ä¼˜åŒ–æ–¹æ¡ˆ
1. ä½¿ç”¨é‡åŒ–ç´¢å¼•ï¼ˆIVF_SQ8, IVF_PQï¼‰
2. å‡å° chunk_size
3. åˆ†æ‰¹å¤„ç†æ–‡æ¡£
4. ä½¿ç”¨ Milvus è€Œé FAISS

### Q5: å¦‚ä½•è¯„ä¼° RAG æ•ˆæœï¼Ÿ

**A:** è¯„ä¼°æŒ‡æ ‡
```python
# 1. æ£€ç´¢å‡†ç¡®ç‡
def evaluate_retrieval(test_queries, expected_docs):
    correct = 0
    for query, expected in zip(test_queries, expected_docs):
        retrieved = vector_store.similarity_search(query, k=4)
        if any(doc.metadata['id'] in expected for doc in retrieved):
            correct += 1
    return correct / len(test_queries)

# 2. ç­”æ¡ˆè´¨é‡ï¼ˆäººå·¥è¯„ä¼°æˆ–ä½¿ç”¨ LLMï¼‰
def evaluate_answer_quality(answer, reference):
    prompt = f"è¯„ä¼°ç­”æ¡ˆè´¨é‡ï¼ˆ1-5åˆ†ï¼‰:\nå‚è€ƒç­”æ¡ˆ:{reference}\nå®é™…ç­”æ¡ˆ:{answer}"
    return llm.invoke(prompt)
```

---

## ğŸ“– å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£
- [LangChain RAG æ•™ç¨‹](https://python.langchain.com/docs/use_cases/question_answering/)
- [Milvus æ–‡æ¡£](https://milvus.io/docs)
- [FAISS æ–‡æ¡£](https://github.com/facebookresearch/faiss)

### è¿›é˜¶å­¦ä¹ 
- é«˜çº§ RAG æŠ€æœ¯ï¼ˆQuery Rewriting, HyDEï¼‰
- å¤šæ¨¡æ€ RAGï¼ˆå›¾åƒ+æ–‡æœ¬ï¼‰
- RAG è¯„ä¼°å’Œä¼˜åŒ–
- ç”Ÿäº§éƒ¨ç½²æœ€ä½³å®è·µ

---

## ğŸ“ ä¸‹ä¸€æ­¥å­¦ä¹ 

å®Œæˆ RAG åŸºç¡€åï¼Œå¯ä»¥å­¦ä¹ ï¼š

1. **é«˜çº§ RAG æŠ€æœ¯**
   - æŸ¥è¯¢æ”¹å†™ï¼ˆQuery Rewritingï¼‰
   - å‡è®¾æ–‡æ¡£åµŒå…¥ï¼ˆHyDEï¼‰
   - åˆ†å±‚æ£€ç´¢
   - è‡ªé€‚åº”æ£€ç´¢

2. **Multi-Agent ç³»ç»Ÿ**
   - å¤šä¸ª Agent åä½œ
   - Agent é€šä¿¡æœºåˆ¶
   - è§’è‰²åˆ†å·¥

3. **LangGraph**
   - å¤æ‚å·¥ä½œæµç¼–æ’
   - çŠ¶æ€ç®¡ç†
   - å¾ªç¯å’Œæ¡ä»¶åˆ†æ”¯

4. **ç”Ÿäº§åŒ–éƒ¨ç½²**
   - API æœåŠ¡å°è£…
   - æ€§èƒ½ä¼˜åŒ–
   - ç›‘æ§å’Œæ—¥å¿—
   - æˆæœ¬æ§åˆ¶

---

æœ‰é—®é¢˜éšæ—¶æŸ¥çœ‹ä»£ç æ³¨é‡Šæˆ–æé—®ï¼ğŸš€

